# -*- coding: utf-8 -*-
"""Submission 3 - Image Classification Model Deployment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1y8L3-APSKcMW3dAE_fAzkrsorbluYnvc

# **Submission 3 - Image Classification Model Deployment**

## **Muhammad Theda Amanda**

Dataset: https://www.kaggle.com/datasets/iarunava/cell-images-for-detecting-malaria

### **Import Libraries**
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import os, io, zipfile, shutil, PIL, datetime, itertools
# %matplotlib inline

from google.colab import files

from sklearn.metrics import confusion_matrix
from keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau

from tensorflow import keras
from tensorflow.keras.utils import plot_model
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator

"""### **Import Dataset with Kaggle**"""

!pip install -q kaggle

uploaded = files.upload()

!chmod 600 /content/kaggle.json

!KAGGLE_CONFIG_DIR=/content/ kaggle datasets download -d iarunava/cell-images-for-detecting-malaria

local_zip = '/content/cell-images-for-detecting-malaria.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/content')
zip_ref.close()

DIR_PATH = '/content/cell_images/'

path_uninfected = DIR_PATH + 'cell_images/Uninfected/'
path_parasitized = DIR_PATH + 'cell_images/Parasitized/'

uninfected_list = os.listdir(path_uninfected)
parasitized_list = os.listdir(path_parasitized)

print('Uninfected: ', len(uninfected_list))
print('Parasitized: ', len(parasitized_list))

"""### **Plot Image**"""

plt.figure(figsize=(20,10))

plt.subplot(2,4,1)

for i in range(1,9):
    plt.subplot(2,4,i)
    image = uninfected_list[i]
    plt.imshow(plt.imread(path_uninfected + image))
    plt.xlabel('uninfected', fontsize=20)

plt.figure(figsize=(20,10))

plt.subplot(2,4,1)

for i in range(1,9):
    plt.subplot(2,4,i)
    image = parasitized_list[i]
    plt.imshow(plt.imread(path_parasitized + image))
    plt.xlabel('parasitized', fontsize=20)

"""### **Data Cleaning**

Check if any non image files are in the folders
"""

for item in uninfected_list:
    file_list = item.split('.')

    if file_list[1] != 'png':
        print('Uninfected folder: ', item)

for item in parasitized_list:
    file_list = item.split('.')

    if file_list[1] != 'png':
        print('Parasitized folder: ',item)

"""Delete non image files"""

os.remove("/content/cell_images/cell_images/Parasitized/Thumbs.db")
os.remove("/content/cell_images/cell_images/Uninfected/Thumbs.db")

"""### **Check Image Sizes**"""

def read_files(startpath):
  image_files = []
  for dirname, dirnames, filenames in os.walk(startpath):
    for filename in filenames:
      image_files.append(os.path.join(dirname, filename))

  return image_files

full_dirs = read_files(DIR_PATH + "cell_images/")

image_sizes = []

for file in full_dirs:
  image = PIL.Image.open(file)
  width, height = image.size
  image_sizes.append(f'{width}x{height}')

unique_sizes = set(image_sizes)

print(f'Size all images: {len(image_sizes)}')
print(f'Size unique images: {len(unique_sizes)}')
print(f'First 5 unique images: \n{list(unique_sizes)[:5]}')

"""### **Data Preprocessing and Data Splitting**"""

datagen = ImageDataGenerator(rescale=1/255.0, validation_split=0.2)

train_data = datagen.flow_from_directory(directory=DIR_PATH + "cell_images",
                                           target_size=(163,142),
                                           class_mode = 'binary',
                                           batch_size = 32,
                                           subset='training')

validation_data = datagen.flow_from_directory(directory=DIR_PATH + "cell_images",
                                           target_size=(163,142),
                                           class_mode = 'binary',
                                           batch_size = 32,
                                           subset='validation',
                                           shuffle = False)

"""### **Modeling**"""

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(16,(3,3), activation = "relu", input_shape=(163,142,3)),
    tf.keras.layers.MaxPooling2D((2,2)),
    tf.keras.layers.Conv2D(32,(3,3), activation = "relu"),
    tf.keras.layers.MaxPooling2D((2,2)),
    tf.keras.layers.Dropout(0.25),
    tf.keras.layers.Conv2D(64,(3,3), activation = "relu"),
    tf.keras.layers.MaxPooling2D((2,2)),
    tf.keras.layers.Dropout(0.25),
    tf.keras.layers.Conv2D(128,(3,3), activation = "relu"),
    tf.keras.layers.Dropout(0.25),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(256, activation = "relu"),
    tf.keras.layers.Dense(128, activation = "relu"),
    tf.keras.layers.Dense(1, activation = "sigmoid")
])

model.summary()

"""### **Compile and Fit Model**"""

model.compile(loss="binary_crossentropy", optimizer ="adam", metrics =['accuracy'])

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard

cp_path = "training_1/cp.ckpt"
cp_dir = os.path.dirname(cp_path)
cp_callback = ModelCheckpoint(filepath=cp_path,
  save_weights_only=True,
  verbose=1)

reduce_lr = ReduceLROnPlateau(
  monitor='val_loss',
  factor=0.6,
  patience=1,
  verbose=1)

log_path = os.path.join('logs','fit')
os.makedirs(log_path,exist_ok=True)
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_path, histogram_freq=1,profile_batch = 100000000)

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.94 and logs.get('val_accuracy')>0.94):
      self.model.stop_training = True
      print("\nThe accuracy of the training set and the validation set has reached > 94%!")

stop_callback = myCallback()

callbacks = [reduce_lr, stop_callback, cp_callback, tensorboard_callback]

history = model.fit(train_data,
                steps_per_epoch = len(train_data),
                epochs=5,
                validation_data=validation_data,
                validation_steps=len(validation_data),
                callbacks=[callbacks]);

"""### **Evaluate Model**

Loading most recent model
"""

latest = tf.train.latest_checkpoint(cp_dir)

model.load_weights(latest)

loss, acc = model.evaluate(validation_data, verbose=2)
print("Restored model, accuracy: {:5.2f}%".format(100*acc))

"""### **Plot Accuracy & Loss**"""

plt.figure(figsize=(15, 5))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'], linestyle='--')
plt.title('Accuracy Model')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Training Set', 'Validation Set'])
plt.grid(linestyle='--', linewidth=1, alpha=0.5)

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'], linestyle='--')
plt.title('Loss Model')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Training Set', 'Validation Set'])
plt.grid(linestyle='--', linewidth=1, alpha=0.5)

plt.show()

"""### **Tensor Board**"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir logs/fit

"""#### **Display Plot**"""

def plot_to_image(figure):
  """This function change the matplotlib plot 'figure' to PNG image"""
  buf = io.BytesIO()
  plt.savefig(buf, format='png')
  plt.close(figure)
  buf.seek(0)
  image = tf.image.decode_png(buf.getvalue(), channels=4)
  image = tf.expand_dims(image, 0)
  return image

!rm -rf logs/plots

# Commented out IPython magic to ensure Python compatibility.
logdir = "logs/plots/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
file_writer = tf.summary.create_file_writer(logdir)

class_names = ['Parasitized', 'Uninfected']

def image_grid():
    """This function to create a plot grid 5x5 from the image and its label"""
    image_batch, label_batch = next(iter(train_data))

    val_image_batch, val_label_batch = next(iter(validation_data))

    figure = plt.figure(figsize=(10,10))

    for i in range(25):
        plt.subplot(5, 5, i + 1, title=class_names[int(label_batch[i])])
        plt.xticks([])
        plt.yticks([])
        plt.grid(False)
        plt.imshow(image_batch[i])
    return figure

figure = image_grid()

with file_writer.as_default():
    tf.summary.image("Training data", plot_to_image(figure), step=0)

# %tensorboard --logdir logs/plots

"""#### **Confusion Matrix**

Setting up the data for the confusion matrix
"""

predictions = model.predict(validation_data, verbose=1)
y_pred = np.round(predictions)
y_true = validation_data.classes

cm = confusion_matrix(y_true, y_pred)

"""Function to plot the confusion matrix taken from the sklearn website"""

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label');

"""Calling the plot function in the confusion matrix data and"""

# Commented out IPython magic to ensure Python compatibility.
cm_plot_labels= ["Uninfected","Parasitized"]

with file_writer.as_default():
  figure = plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')
  cm_image = plot_to_image(figure)
  tf.summary.image("Confusion Matrix", cm_image, step=0)

# %tensorboard --logdir logs/plots

"""### **Save Model to TF-Lite Format**"""

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

with open('model.tflite', 'wb') as f:
  f.write(tflite_model)